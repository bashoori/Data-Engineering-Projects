# ğŸ“„ LinkedIn Profile Scraper

A cloud-based Python automation project that scrapes LinkedIn profile information using **Selenium**, runs entirely in **GitHub Codespaces**, and is scheduled to execute daily using **GitHub Actions**. Scraped data is saved in a structured CSV file for analysis, reporting, or integration with Google Sheets.

---

## ğŸš€ Features
- Scrapes name and job title from LinkedIn public profiles
- Written and tested entirely in **GitHub Codespaces** (no local setup required)
- **Automated daily execution** with GitHub Actions
- Saves data into a `linkedin_results.csv` file
- Lightweight, headless browser automation using Selenium

---

## ğŸ§° Tech Stack
- Python 3.10+
- Selenium (Chrome WebDriver)
- Pandas (for CSV export)
- GitHub Codespaces
- GitHub Actions (for scheduling)

---

## ğŸ“ Project Structure
```
linkedin-scraper/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ scrape.yml
â”œâ”€â”€ scraper.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ linkedin_results.csv (output)
```

---

## ğŸ”§ Setup Instructions

### 1. Clone the Repository & Open Codespace
```bash
git clone https://github.com/yourusername/linkedin-scraper.git
cd linkedin-scraper
```
Then open it as a **Codespace** from GitHub.

### 2. Add Your LinkedIn URLs to `scraper.py`
Replace the placeholder URLs in the script with real profile URLs you want to scrape.

### 3. Add Dependencies
Create `requirements.txt`:
```
selenium
pandas
```

### 4. Configure GitHub Actions Scheduler
Add this file: `.github/workflows/scrape.yml`
```yaml
name: Daily LinkedIn Scrape

on:
  schedule:
    - cron: '0 9 * * *'  # every day at 9 AM UTC
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - run: pip install -r requirements.txt
      - run: python scraper.py
```

---

## ğŸ“Š Output
- The script creates a `linkedin_results.csv` file in the repo root.
- Columns include `URL`, `Name`, `Headline`

---

## ğŸ“Œ Notes
- You must run the scraper **headless** to work with GitHub Actions.
- For full profile data (like work history), login automation or cookies may be needed (âš ï¸ use responsibly).

---

## âœ… TODO / Improvements
- [ ] Add Google Sheets export via API
- [ ] Add rotating LinkedIn session cookies
- [ ] Add logging and error handling

---

## ğŸ“¬ Contact
Created by [Bita Ashoori](mailto:bitadigitalmarketer@gmail.com) â€” feel free to reach out for custom scraping or automation projects!
